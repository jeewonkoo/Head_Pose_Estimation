{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 코더블 첫번째 숙제\n",
    "### Perceptron Training\n",
    "\n",
    "저희는 미팅에서 설명드렸던 것과 같이 Perceptron 이라는 Linear Classifier을 implement하여 Binary Classification 작업을 할 것입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency functions\n",
    "DO NOT EDIT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def load_dataset(filename, extra=False):\n",
    "    A = unpickle(filename)\n",
    "    X = A[b'data'] / 255 # feature scale the data to range 0-1\n",
    "    Y = A[b'labels']\n",
    "\n",
    "    # make small dataset for knn\n",
    "    if extra:\n",
    "        X = X[: 1000]\n",
    "        Y = Y[: 1000]\n",
    "\n",
    "    test_size = int(0.25 * len(X)) # set aside 25% for testing\n",
    "    X_test = X[:test_size]\n",
    "    Y_test = Y[:test_size]\n",
    "    X = X[test_size:]\n",
    "    Y = Y[test_size:]\n",
    "\n",
    "    animals = [2,3,4,5,6,7]\n",
    "    Y = np.array([Y[i] in animals for i in range(len(Y))])\n",
    "    Y_test = np.array([Y_test[i] in animals for i in range(len(Y_test))])\n",
    "\n",
    "    return X,Y,X_test,Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracies(predicted_labels,dev_labels):\n",
    "    if not isinstance(predicted_labels, list):\n",
    "        print('Predict labels must be list')\n",
    "        assert False\n",
    "    yhats = predicted_labels\n",
    "    if len(yhats) != len(dev_labels):\n",
    "        print('Predict labels must have the same length as actual labels!')\n",
    "        assert False\n",
    "    if not all([(y == 0 or y == 1) for y in yhats]):\n",
    "        print('Predicted labels must only contain 0s or 1s')\n",
    "        assert False\n",
    "    accuracy = np.mean(yhats == dev_labels)\n",
    "    tp = np.sum([yhats[i] == dev_labels[i] and yhats[i] == 1 for i in range(len(yhats))])\n",
    "    precision = tp / np.sum([yhats[i]==1 for i in range(len(yhats))])\n",
    "    recall = tp / (np.sum([yhats[i] != dev_labels[i] and yhats[i] == 0 for i in range(len(yhats))]) + tp)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    print(\"Accuracy:\",accuracy)\n",
    "    print(\"F1-Score:\",f1)\n",
    "    print(\"Precision:\",precision)\n",
    "    print(\"Recall:\",recall)\n",
    "\n",
    "    return accuracy,f1,precision,recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your functions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Perceptron Algorithm\n",
    "\n",
    "#### hints\n",
    "1. In this case of perceptron training algorithm, we will be using np.sign() function as a scoring function.\n",
    "    * If sign(Wx + b) > 0, prediction = 1\n",
    "    * If sign(Wx + b) <= 0, prediction = 0\n",
    "2. Initialize the weights and bias a zeros.\n",
    "3. You can either use weight and bias as seperate variables or use the \"bias trick\"!\n",
    "4. weight update function: weights(t + 1) = weights(t) + learning_rate * (expected_i – predicted_) * input_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "train_set = A Numpy array of 32x32x3 images of shape [7500, 3072].\n",
    "            this can be thought of as a list of N 1 x D vectors where D stands\n",
    "            for the dimension of the image where 32*32*3 = 3072 and the \n",
    "            N is the total number of images in the training set = 7500.\n",
    "\n",
    "train_labels = List of labels coresponding to the training set.\n",
    "               Range of labels [1, 0] if the image contains a picture of an animal, label = 1, else = 0.\n",
    "\n",
    "dev_set = A Numpy array of 32*32*3 images of shape[2500, 3072].\n",
    "          It is the same format as train_set.\n",
    "\"\"\"\n",
    "\n",
    "# def trainPerceptron(train_set, train_labels, learning_rate, max_iter):\n",
    "#     # TODO: Write your code here\n",
    "#     # return the trained weight and bias parameters\n",
    "    \n",
    "#     K = 2\n",
    "#     D = len(train_set[0]) #3072\n",
    "#     N = len(train_set)    #7500\n",
    "#     W = np.zeros((K, D))  #2, 3072\n",
    "#     b = np.zeros((K, 1))\n",
    "\n",
    "    #K X D, D X 1, , K + 1\n",
    "    \n",
    "#     for _ in range(max_iter): \n",
    "#         for i in range(len(train_set)):\n",
    "# #             prediction = 1 if np.sign(np.dot(W, train_set[i])+b).all() > 0 else 0\n",
    "            \n",
    "#             score = np.sign(np.dot(W, train_set[i])+b).any()\n",
    "            \n",
    "#             if train_labels[i] == 1: prediction = 1\n",
    "#             else: prediction = -1\n",
    "    \n",
    "#             if prediction != score :\n",
    "#                 W += learning_rate * (train_labels[i] - prediction) * train_set[i]\n",
    "#                 b += learning_rate * prediction\n",
    "        \n",
    "#     return W, b\n",
    "\n",
    "def trainPerceptron(train_set, train_labels, learning_rate, max_iter):\n",
    "    # TODO: Write your code here\n",
    "    # return the trained weight and bias parameters\n",
    "    W=[0]*(len(train_set[0]))\n",
    "    b=0\n",
    "    for m in range(max_iter):\n",
    "        for i in range(len(train_set)):\n",
    "            img = train_set[i]\n",
    "            sign = np.sign(np.dot(W,img)+b)\n",
    "        \n",
    "            if train_labels[i]==1:\n",
    "                sign_ = 1\n",
    "            else:\n",
    "                sign_ = -1\n",
    "\n",
    "            if sign != sign_:\n",
    "                W += learning_rate*sign_*img\n",
    "                b += learning_rate*sign_\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Predict w/ Perceptron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyPerceptron(train_set, train_labels, dev_set, learning_rate, max_iter):\n",
    "    # TODO: Write your code here\n",
    "    # Train perceptron model and return predicted labels of development set\n",
    "    \n",
    "    W, b = trainPerceptron(train_set, train_labels, learning_rate, max_iter)\n",
    "    \n",
    "    predictions = []\n",
    "#     for _ in range(max_iter):\n",
    "    for i in range(len(dev_set)):\n",
    "        prediction = 1 if np.sign((np.dot(W, dev_set[i]) + b)).any() > 0 else 0 \n",
    "#         predictions.append(prediction)\n",
    "        \n",
    "        if prediction == 1: predictions.append(1)\n",
    "        else: predictions.append(0)\n",
    "        \n",
    "    return predictions\n",
    "        \n",
    "# def classifyPerceptron(train_set, train_labels, dev_set, learning_rate, max_iter):\n",
    "#     # TODO: Write your code here\n",
    "#     # Train perceptron model and return predicted labels of development set\n",
    "#     W,b = trainPerceptron(train_set, train_labels, learning_rate, max_iter)\n",
    "#     dev_labels = []\n",
    "\n",
    "#     for i in range(len(dev_set)):\n",
    "#         img = dev_set[i]\n",
    "#         if np.dot(W,img)+b > 0:\n",
    "#             sign = 1\n",
    "#         else:\n",
    "#             sign = -1\n",
    "#         if sign == 1:\n",
    "#             dev_labels.append(1)\n",
    "#         else:\n",
    "#             dev_labels.append(0)\n",
    "#     return dev_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "Change as you wish to improve the performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.01\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train!\n",
    "\n",
    "#### Try to get over 0.75 accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(lrate, epochs):\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    train_set, train_labels, dev_set,dev_labels = load_dataset(\"mp5_data\")\n",
    "    pred_p = classifyPerceptron(train_set, train_labels, dev_set, lrate, epochs)\n",
    "    accuracy,f1,precision,recall = compute_accuracies(pred_p, dev_labels)\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    print(f'Time taken for Perceptron to execute training and classification: {end_time - start_time:.3f} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5964\n",
      "F1-Score: 0.7471811576046105\n",
      "Precision: 0.5964\n",
      "Recall: 1.0\n",
      "Time taken for Perceptron to execute training and classification: 0.434 seconds\n"
     ]
    }
   ],
   "source": [
    "train(LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, train_labels, dev_set,dev_labels = load_dataset(\"mp5_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 2\n",
    "D = len(train_set[0]) #3072\n",
    "N = len(train_set)    #7500\n",
    "W = np.zeros((K, D))\n",
    "b = np.zeros((K, 1))\n",
    "len(W[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a46b1207f395e7ab71922af296ffcc2c3411c9e4e26baa3576245c832e7db8a2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
